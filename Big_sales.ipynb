{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Big Sales Prediction using Random Forest Regressor\n"
      ],
      "metadata": {
        "id": "dqZ-nhxiganh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------"
      ],
      "metadata": {
        "id": "gScHkw6jjrLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Objective**\n",
        "\n",
        "\n",
        "The objective of this program is to develop and evaluate a predictive model for forecasting sales using a Random Forest Regressor. This involves:\n",
        "\n",
        "* Data Acquisition: Import and load a dataset containing sales and related features.\n",
        "* Data Exploration and Visualization: Analyze and visualize the dataset to understand its structure, distribution, and relationships between variables.\n",
        "* Data Preprocessing: Clean and preprocess the data, including handling missing values, encoding categorical variables, and scaling features if necessary.\n",
        "* Feature and Target Definition: Define the target variable (sales) and feature variables (predictors) for the model.\n",
        "* Model Training and Testing: Split the data into training and testing sets, train a Random Forest Regressor model on the training set, and evaluate its performance on the testing set.\n",
        "* Model Evaluation: Assess the model's accuracy and effectiveness using metrics such as Mean Squared Error (MSE) and R-squared (RÂ²) score.\n",
        "* Prediction: Use the trained model to make sales predictions on new or unseen data.\n",
        "* Feature Importance Analysis: Analyze the importance of different features in predicting sales to gain insights into which variables are most influential."
      ],
      "metadata": {
        "id": "Xns_rCdhh-vZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9sPvnFM1iI9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Source**"
      ],
      "metadata": {
        "id": "-Vbnt9CciKJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Source refers to where the dataset is coming from. You might use datasets from:\n",
        "\n",
        "\n",
        "*   Public Datasets: Websites like Kaggle, UCI Machine Learning Repository, etc.\n",
        "*   Company Databases: If you're working within a company, you may pull data from internal databases or CRM systems.\n",
        "\n",
        "*   APIs: Some sales data might be pulled directly from APIs provided by sales platforms or analytics tools."
      ],
      "metadata": {
        "id": "FZMEf6tE95Sy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Library**"
      ],
      "metadata": {
        "id": "r7GrZzX0iTlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # For data manipulation\n",
        "import numpy as np   # For numerical operations\n",
        "import matplotlib.pyplot as plt  # For data visualization\n",
        "import seaborn as sns  # For statistical data visualization\n",
        "from sklearn.model_selection import train_test_split  # For splitting data\n",
        "from sklearn.ensemble import RandomForestRegressor  # For the regression model\n",
        "from sklearn.metrics import mean_squared_error, r2_score  # For evaluation\n"
      ],
      "metadata": {
        "id": "UkK6NH9DiW-X"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Data**\n",
        "\n",
        "data = pd.read_csv('sales_data.csv')\n"
      ],
      "metadata": {
        "id": "9lHPQj1XiOUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Describe Data**\n",
        "\n",
        "print(data.info())\n",
        "\n",
        "print(data.describe())"
      ],
      "metadata": {
        "id": "7PUnimBoiX-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Visualization**"
      ],
      "metadata": {
        "id": "UqfyPOCYiiww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sns.histplot(data['Sales'])\n",
        "plt.show()\n",
        "\n",
        "sns.scatterplot(x='Feature1', y='Sales', data=data)\n",
        "plt.show()\n",
        "\n",
        "sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iyb96Ypw_Uh8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Data Preprocessing**"
      ],
      "metadata": {
        "id": "W1K7dUDL_-_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "data = data.dropna()  # Dropping rows with missing values\n",
        "data = pd.get_dummies(data, drop_first=True)  # One-hot encoding categorical variables\n"
      ],
      "metadata": {
        "id": "gbqz_gWd_-_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define Target Variable (y) and Feature Variables (X)**"
      ],
      "metadata": {
        "id": "2jXJpdAuiwYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "X = data.drop('Sales', axis=1)  # Features\n",
        "\n",
        "y = data['Sales']  # Target variable\n",
        "\n"
      ],
      "metadata": {
        "id": "bH61LyFs_7cM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train Test Split**"
      ],
      "metadata": {
        "id": "90_0q_Pbi658"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "zUniD65OAasO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modeling**"
      ],
      "metadata": {
        "id": "cIhyseNria7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "MOAD8HR8AjsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Evaluation**"
      ],
      "metadata": {
        "id": "vhAwWfG0jFun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "print(f\"R^2 Score: {r2}\")\n"
      ],
      "metadata": {
        "id": "-cq7KTloApHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prediction**"
      ],
      "metadata": {
        "id": "8AzwG7oLjiQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "new_data = pd.DataFrame({\n",
        "\n",
        "})\n",
        "\n",
        "predictions = model.predict(new_data)\n",
        "\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "id": "b5xZ5YGiA215"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Explaination**"
      ],
      "metadata": {
        "id": "SBo38CJZjlEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Regressor is an ensemble learning method that combines multiple decision trees to improve prediction accuracy. It works well with both numerical and categorical data and is robust to overfitting. Key points to consider:\n",
        "\n"
      ],
      "metadata": {
        "id": "Ybi8FR9Kjv00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "> importances = model.feature_importances_\n",
        "features = X.columns\n",
        "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
        "print(feature_importance_df.sort_values(by='Importance', ascending=False))\n",
        "\n"
      ],
      "metadata": {
        "id": "EkUKKZQRBIau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Model Tuning: Hyperparameters like n_estimators (number of trees) and max_depth (depth of trees) can be tuned to improve performance.\n"
      ],
      "metadata": {
        "id": "8cP5KMgMBKve"
      }
    }
  ]
}